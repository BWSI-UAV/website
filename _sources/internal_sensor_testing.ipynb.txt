{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting Sensor Feeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will learn more about how to graph and interpret sensor data from the Intel RTF Drone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Translational Movement (Accelerometer)\n",
    "The inertial measurement unit (IMU) on board the Intel RTF Drone has an accelerometer that can measure translational accelerations to relatively high precision. The following steps will show you how to access this data in QGroundControl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the QGroundControl top menu bar, select Analyze under Widgets. </li>\n",
    "\n",
    "![widgets.png](https://github.com/BWSI-UAV/website/blob/master/docs/images/widgets.png?raw=true)\n",
    "\n",
    "* In Analyze, enter 'acc' into the filter box. \n",
    "\n",
    "\n",
    "![acc.png](https://github.com/BWSI-UAV/website/blob/master/docs/images/acc.png?raw=true)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Select the check box for IMU.zacc, and verify that the resulting graph is close to -9.81 m/s^2 (gravity)\n",
    "\n",
    "\n",
    "\n",
    "![zacc.png](https://github.com/BWSI-UAV/website/blob/master/docs/images/zacc.png?raw=true)\n",
    "\n",
    "* Now tap the table surrounding the drone and see if IMU.zacc changes. Try tapping underneath the drone from below the table. As you may notice, tapping the drone in the same plane as the drone will not cause large changes in IMU.zacc.\n",
    "\n",
    "* Deselect IMU.zacc and select IMU.xacc and IMU.yacc. Verify that the resulting graphs are close to zero. Now try those same taps with IMU.xacc and IMU.yacc. As you may have guessed, taps in the plane affect these values much more significantly than taps below or above the drone.\n",
    "\n",
    "\n",
    "\n",
    "![xacc_yacc.png](https://github.com/BWSI-UAV/website/blob/master/docs/images/xacc_yacc.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Angular Motion (Gyroscope)\n",
    "* In Analyze, select roll, pitch, and yaw by selecting them using the filter box.\n",
    "\n",
    "* First, try changing the yaw value by rotating the drone around the z axis (imagine a circle under the drone on the table, and rotate it around that circle.) The yaw value should cycle between pi/2 and negative pi/2.\n",
    "* Next, try rolling the drone by rotating it around the x axis (goes from the power button to the camera) and watching the roll value in Analyze.\n",
    "* Finally, try pitching the drone by rotating around the y axis (the one axis you haven't tried yet, goes from one side of the drone to the other) and watching the pitch value change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out Optical Flow\n",
    "Optical flow sensors help the drone estimate its current position by tracking features on the ground (you will learn more about the theory of optical flow later in the course.)\n",
    "\n",
    "Here are the steps to activating optical flow on the drone.\n",
    "* Plug in the Teraranger USB cable to the drone USB port. Ask an instructor for help if need be.\n",
    "* SSH into the drone from the team laptop. Run the following commands\n",
    "\n",
    "```\n",
    "sudo systemctl start aero-teraranger.service\n",
    "sudo systemctl start aero-optical-flow.service\n",
    "```\n",
    "\n",
    "Alternatively, you can run\n",
    "```\n",
    "cd ~/bwsi-uav/catkin_ws/src/aero-optical-flow/build\n",
    "roscore &\n",
    "sudo -E aero-optical-flow &\n",
    "systemctl start aero-teraranger.service\n",
    "```\n",
    "* Now return to QGroundControl on the laptop. Open `Widgets > MAVLink Inspector` \n",
    "![mavlink.png](https://github.com/BWSI-UAV/website/blob/master/docs/images/mavlink.png?raw=true)\n",
    "* Scroll to OPTICAL_FLOW_RAD, and expand it. Make sure the quality is > 100 (hold the drone over a textured surface to increase quality). \n",
    "![optical-flow.png](https://github.com/BWSI-UAV/website/blob/master/docs/images/optical-flow.png?raw=true)\n",
    "* Now go to LOCAL_POSITION_NED, and expand it. \n",
    "![local-position.png](https://github.com/BWSI-UAV/website/blob/master/docs/images/local-position.png?raw=true)\n",
    "* If you move the drone over a textured surface, you'll be able to see the position estimate of the drone changing as new information comes in from the optical flow sensor, distance sensor, and IMU. \n",
    "\n",
    "This is how the drone stabilizes itself in position control mode. It tries to maintain whatever initial position it reads, and RC control inputs modify that set position, causing the drone to center itself on a new point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
