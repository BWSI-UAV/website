{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Following\n",
    "In this document, you will learn how to put together your parameterization of a line detected from the downward camera with a flight controller to accurately follow a line.\n",
    "\n",
    "Key tools:\n",
    "\n",
    "\n",
    "\n",
    "- `opencv`\n",
    "- Closed-loop velocity control\n",
    "- `rosmsg`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Setup for Line Following\n",
    "### Launching Line Following\n",
    "You will be using a launch file to execute line following code called `detect_track.launch`. This launch file will be provided to you in `aero_control`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "`detect_track.launch` does a few things:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Sets target MAV frame for velocity commands to `bu`\n",
    "- Initializes `detector.py` and `tracker.py`\n",
    "- Launches MAVROS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### PID Tuning\n",
    "Start thinking, as you are writing line following code, about how much you want your drone to respond to moving off of the line. Should its response be aggressive? Consider the pros and cons of aggressive vs non-aggressive control behavior. Your $K_{P_x}$ and $K_{P_y}$ should always start below 1.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking Down Line Following\n",
    "### Computer Vision (`detector.py`)\n",
    "Your computer vision algorithms must be precise and accurate when detecting the LED strip that will feature in the final race. \n",
    "\n",
    "Be sure to test your existing CV algorithms by publishing an Image message on `/line/img` that shows the line being tracked. You will be testing this on a `rosbag` **before you have the opportunity to fly your code**. Notify an instructor once you have the proper image displayed on top of the `rosbag` we have provided you. You will then be permitted to move on to the next stage of development in this task.\n",
    "\n",
    "### Control Systems (`tracker.py`)\n",
    "You will be controlling two degrees of freedom in the line following task: $x$ and $y$\n",
    "\n",
    "Using information about the image that the downward camera is publishing, you will calculate the error between your desired position on the line and your current position. \n",
    "\n",
    "This can be broken down into a few steps:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Find the point representing the center of the image $p_{frame-center}$, and the point representing the center of the line $p_{line-center}$ (in pixel coordinates)\n",
    "- Find the unit vector in the direction of the line $\\vec{r}_{line-unit}$ (using `vx` and `vy`)\n",
    "- Find the point on the line closest to the center of the frame $p_{line-closest-center}$ \n",
    "- Extrapolate a point forward (from $p_{line-closest-center}$) on the line using the unit vector in the direction of the line, making sure that the unit vector is positive $p_{target}$\n",
    "- Calculate the vector from the center of the frame to the extrapolated point (this represents error) $\\vec{r}_{to-target}$\n",
    "- Calculate $c_x(t)$ and $c_y(t)$ using your pre-determined $K_P$ values.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Diagram:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![line_diagram.jpg](https://github.com/BWSI-UAV/website/blob/master/docs/images/line_diagram.jpg?raw=true)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Checkpoints\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Graph error vs. time on the provided `rosbag`. An instructor will check to see that the error graphs are consistent with actual data. You should use RQT's built in graph mechanism to view the output of your error function (publish a Vector3 on `/line/error`). Ask an instructor for more details, and notify us once finished.\n",
    "- Output velocity commands to `/mavros/setpoint_velocity/cmd_vel` and `rostopic echo` them using the `rosbag`. An instructor will verify that the velocity commands are successful.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "After these checkpoints, you will be allowed to fly your code and test it to tune your $K_P$ constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Specification\n",
    "You will be asked to fly on a straight line of LED lights. We will be limiting flights to 8 seconds, after which instructors will land your drone to avoid errors caused by attempting curved line following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
